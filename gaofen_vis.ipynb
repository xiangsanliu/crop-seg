{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils.model_tools import ModelValidator\n",
    "from utils.my_logging import Logger\n",
    "from data.dataloader import build_dataloader\n",
    "from model import build_model\n",
    "from utils import parse_args\n",
    "from tqdm import tqdm\n",
    "import configs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "config_file = 'segformer_b4_gaofen'\n",
    "weight = 'work/models/segformer_b4_gaofen/2021-09-14T16:40:39.pkl'\n",
    "\n",
    "config = getattr(configs, config_file)\n",
    "model = build_model(config[\"model\"])\n",
    "cfg_test_pipeline = config[\"test_pipeline\"]\n",
    "cfg_test_pipeline['dataloader']['batch_size'] = 1\n",
    "cfg_test_pipeline['dataloader']['num_workers'] = 1\n",
    "cfg_test_pipeline['dataloader']['shuffle'] = True\n",
    "\n",
    "test_loader = build_dataloader(cfg_test_pipeline)\n",
    "train_config = config[\"train_config\"]\n",
    "device = train_config[\"device\"]\n",
    "model.load_state_dict(torch.load(weight, map_location=\"cpu\"))\n",
    "device='cpu'\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Segformer(\n",
       "  (encoder): mit_b4(\n",
       "    (patch_embed1): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed2): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed3): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed4): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (block1): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "    (block2): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "    (block3): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (25): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (26): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "    (block4): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "          )\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): SegFormerHead(\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (linear_c4): MLP(\n",
       "      (proj): Linear(in_features=512, out_features=768, bias=True)\n",
       "    )\n",
       "    (linear_c3): MLP(\n",
       "      (proj): Linear(in_features=320, out_features=768, bias=True)\n",
       "    )\n",
       "    (linear_c2): MLP(\n",
       "      (proj): Linear(in_features=128, out_features=768, bias=True)\n",
       "    )\n",
       "    (linear_c1): MLP(\n",
       "      (proj): Linear(in_features=64, out_features=768, bias=True)\n",
       "    )\n",
       "    (linear_fuse): Sequential(\n",
       "      (0): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (linear_pred): Conv2d(768, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (upsample): Upsample(scale_factor=4.0, mode=bilinear)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "with torch.no_grad():\n",
    "    for val_img, val_mask in tqdm(\n",
    "        test_loader, total=len(test_loader), desc=\"Valid\", ncols=100\n",
    "    ):\n",
    "        val_img = val_img.to(device)\n",
    "        # val_mask = val_mask.to(device)\n",
    "\n",
    "        pred_img_1 = model(val_img)\n",
    "\n",
    "        # pred_img_2 = model(torch.flip(val_img, [-1]))\n",
    "        # pred_img_2 = torch.flip(pred_img_2, [-1])\n",
    "\n",
    "        # pred_img_3 = model(torch.flip(val_img, [-2]))\n",
    "        # pred_img_3 = torch.flip(pred_img_3, [-2])\n",
    "\n",
    "        # pred_img_4 = model(torch.flip(val_img, [-1, -2]))\n",
    "        # pred_img_4 = torch.flip(pred_img_4, [-1, -2])\n",
    "\n",
    "        # pred_list = pred_img_1 + pred_img_2 + pred_img_3 + pred_img_4\n",
    "        pred_list = pred_img_1\n",
    "        pred_list = torch.argmax(pred_list.cpu(), 1).byte().numpy()\n",
    "        \n",
    "        gt = val_mask.data.numpy()\n",
    "        \n",
    "        vis = np.concatenate([gt[0], pred_list[0]], axis=0)\n",
    "        vis = np.clip(vis, a_min=0.0, a_max=1.0)\n",
    "        print(vis.shape)\n",
    "        plt.imsave(\"vis/valid.jpg\", vis)\n",
    "        time.sleep(2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Valid:   0%|                                                                | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1024, 512)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Valid:   0%|▏                                                       | 1/400 [00:08<55:15,  8.31s/it]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_102815/4233514889.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# val_mask = val_mask.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mpred_img_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# pred_img_2 = model(torch.flip(val_img, [-1]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch-1.8.1/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/crop-seg/model/segformer/segformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch-1.8.1/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/crop-seg/model/segformer/mix_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;31m# x = self.head(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/crop-seg/model/segformer/mix_transformer.py\u001b[0m in \u001b[0;36mforward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_embed3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch-1.8.1/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/crop-seg/model/segformer/mix_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, H, W)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch-1.8.1/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/crop-seg/model/segformer/mix_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, H, W)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('torch-1.8.1': conda)"
  },
  "interpreter": {
   "hash": "0439cc1fb3ca274a7e2df5ee278b62dcfe3f14c761deedd8586e63968912a454"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}